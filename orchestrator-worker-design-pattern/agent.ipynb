{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1efe6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Literal, TypedDict\n",
    "from pydantic import Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from typing import Annotated, List\n",
    "import operator\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.types import Send\n",
    "from IPython.display import Markdown, Image\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8959e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema for structured output to use in planning\n",
    "class Section(BaseModel):\n",
    "    name: str = Field(\n",
    "        description=\"Name for this section of the report.\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"Brief overview of the main topics and concepts to be covered in this section.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section] = Field(\n",
    "        description=\"Sections of the report.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c15e95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedState(TypedDict):\n",
    "    research_topic: str\n",
    "    model: ChatOpenAI\n",
    "    sections: list[Section]\n",
    "    section_contents: Annotated[list[str], operator.add]\n",
    "    final_report: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52bb2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(shared_state: SharedState) -> SharedState:\n",
    "    shared_state['model'] = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    return shared_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c405ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orchestrator(shared_state: SharedState) -> SharedState:\n",
    "    model = shared_state['model']\n",
    "    orchestrator_prompt = ChatPromptTemplate.from_template(\n",
    "        \"Create a detailed outline for a research report on the topic of {research_topic}. \"\n",
    "        \"Break the report down into sections, each with a name and brief description. \"\n",
    "        \"Limit the report to at max 5 sections.\"\n",
    "    )\n",
    "\n",
    "    model_with_structured_output = model.with_structured_output(Sections)\n",
    "    retrieval_grader = orchestrator_prompt | model_with_structured_output\n",
    "    result = retrieval_grader.invoke(\n",
    "        {\n",
    "            \"research_topic\": shared_state['research_topic'],\n",
    "        }\n",
    "    )\n",
    "    shared_state['sections'] = [section for section in result.sections]\n",
    "\n",
    "    return shared_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9cdab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "shared_state = build_model({'research_topic': 'The impact of AI on modern education.'})\n",
    "shared_state = orchestrator(shared_state)\n",
    "\n",
    "shared_state['sections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9a2a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worker state\n",
    "class WorkerState(TypedDict):\n",
    "    section: Section\n",
    "    model: ChatOpenAI\n",
    "    completed_sections: Annotated[list, operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d7a5b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(worker_state: WorkerState) -> SharedState:\n",
    "    \"\"\"Worker writes a section of the report\"\"\"\n",
    "    print(f\"\\nWorker Spawned! Working on section: {worker_state['section'].name}\")\n",
    "    model = worker_state['model']\n",
    "    section = worker_state['section']\n",
    "    # Generate section\n",
    "    section = model.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Write a report section following the provided name and description. Include no preamble for each section. Use markdown formatting.\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=f\"Here is the section name: {section.name} and description: {section.description}\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Write the updated section to completed sections\n",
    "    return {\"section_contents\": [section.content]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db1966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional edge function to create llm_call workers that each write a section of the report\n",
    "def spawn_workers(shared_state: SharedState):\n",
    "    \"\"\"Assign a worker to each section in the plan\"\"\"\n",
    "    model = shared_state[\"model\"]\n",
    "    # Kick off section writing in parallel via Send() API\n",
    "    return [\n",
    "        Send(\"worker\", {\"section\": section, \"model\": model}) \n",
    "        for section in shared_state[\"sections\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5767c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesizer(shared_state: SharedState):\n",
    "    \"\"\"Synthesize full report from sections\"\"\"\n",
    "\n",
    "    # List of completed sections\n",
    "    section_contents = shared_state[\"section_contents\"]\n",
    "\n",
    "    # Format completed section to str to use as context for final sections\n",
    "    completed_report_sections = \"\\n\\n---\\n\\n\".join(section_contents)\n",
    "\n",
    "    return {\"final_report\": completed_report_sections}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0eeaed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_workflow():\n",
    "    # Build workflow\n",
    "    orchestrator_worker_builder = StateGraph(SharedState)\n",
    "\n",
    "    # Add the nodes\n",
    "    orchestrator_worker_builder.add_node(\"build_model\", build_model)\n",
    "    orchestrator_worker_builder.add_node(\"orchestrator\", orchestrator)\n",
    "    orchestrator_worker_builder.add_node(\"worker\", worker)\n",
    "    orchestrator_worker_builder.add_node(\"synthesizer\", synthesizer)\n",
    "\n",
    "    # Add edges to connect nodes\n",
    "    orchestrator_worker_builder.add_edge(START, \"build_model\")\n",
    "    orchestrator_worker_builder.add_edge(\"build_model\", \"orchestrator\")\n",
    "    orchestrator_worker_builder.add_conditional_edges(\n",
    "        \"orchestrator\", spawn_workers, [\"worker\"]\n",
    "    )\n",
    "    orchestrator_worker_builder.add_edge(\"worker\", \"synthesizer\")\n",
    "    orchestrator_worker_builder.add_edge(\"synthesizer\", END)\n",
    "\n",
    "    # Compile the workflow\n",
    "    return orchestrator_worker_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "188ed77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orchestrator_worker = build_workflow()\n",
    "\n",
    "# Show the workflow\n",
    "display(Image(orchestrator_worker.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfe94d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Worker Spawned! Working on section: Introduction to LLM Scaling Laws\n",
      "Worker Spawned! Working on section: Historical Context and Development\n",
      "\n",
      "\n",
      "Worker Spawned! Working on section: Theoretical Foundations of Scaling Laws\n",
      "\n",
      "Worker Spawned! Working on section: Empirical Evidence and Case Studies\n",
      "\n",
      "Worker Spawned! Working on section: Future Directions and Implications\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Introduction to LLM Scaling Laws\n",
       "\n",
       "Large Language Models (LLMs) have become a cornerstone of modern artificial intelligence, driving advancements in natural language processing, machine translation, and conversational agents. These models, characterized by their vast number of parameters and extensive training datasets, have demonstrated remarkable capabilities in understanding and generating human-like text. As the field progresses, understanding the principles that govern the performance of these models becomes increasingly crucial. This is where the concept of scaling laws comes into play.\n",
       "\n",
       "Scaling laws in the context of LLMs refer to the empirical relationships that describe how the performance of a model improves as a function of its size, the amount of data it is trained on, and the computational resources utilized. These laws provide a framework for predicting the behavior of LLMs as they are scaled up, offering insights into the trade-offs between model size, data, and compute power.\n",
       "\n",
       "The importance of scaling laws lies in their ability to guide the development of more efficient and effective LLMs. By understanding these relationships, researchers and practitioners can make informed decisions about how to allocate resources for training and deploying models. This can lead to more cost-effective strategies for achieving desired performance levels, ultimately accelerating the pace of innovation in the field.\n",
       "\n",
       "In this section, we will explore the foundational concepts of scaling laws and their implications for LLMs. We will discuss how these laws have been derived, the key variables involved, and the insights they provide into the future trajectory of language model development. This introduction sets the stage for a detailed analysis of scaling laws, offering a comprehensive understanding of their role in shaping the capabilities and limitations of large language models.\n",
       "\n",
       "---\n",
       "\n",
       "## Historical Context and Development\n",
       "\n",
       "The development of Large Language Models (LLMs) is a fascinating journey that reflects the broader evolution of artificial intelligence and machine learning. This section explores the historical context and development of LLMs, highlighting key milestones, influential research papers, and the progression of model sizes and capabilities over time.\n",
       "\n",
       "### Early Foundations\n",
       "\n",
       "The roots of LLMs can be traced back to the early work on artificial neural networks and natural language processing (NLP). In the 1950s and 1960s, researchers like Frank Rosenblatt and Marvin Minsky laid the groundwork with the development of perceptrons and early neural network models. However, it wasn't until the advent of more sophisticated algorithms and increased computational power in the late 20th century that significant progress was made.\n",
       "\n",
       "### The Emergence of Deep Learning\n",
       "\n",
       "The 2000s marked a turning point with the resurgence of interest in neural networks, driven by the success of deep learning. The introduction of the backpropagation algorithm and the availability of large datasets enabled the training of deeper networks. In 2013, the paper \"Efficient Estimation of Word Representations in Vector Space\" by Mikolov et al. introduced Word2Vec, a model that revolutionized NLP by learning word embeddings, setting the stage for more complex language models.\n",
       "\n",
       "### The Transformer Revolution\n",
       "\n",
       "A pivotal moment in the development of LLMs came in 2017 with the introduction of the Transformer architecture by Vaswani et al. in the paper \"Attention is All You Need.\" This architecture, which relies on self-attention mechanisms, allowed for more efficient training of language models and significantly improved performance on a variety of NLP tasks. The Transformer model became the foundation for subsequent LLMs, enabling the scaling of models to unprecedented sizes.\n",
       "\n",
       "### Scaling Laws and Model Growth\n",
       "\n",
       "The concept of scaling laws, which describe how model performance improves with increased size and data, became a central theme in the development of LLMs. In 2020, Kaplan et al. published \"Scaling Laws for Neural Language Models,\" which provided empirical evidence that larger models trained on more data tend to perform better. This insight drove the development of increasingly large models, such as OpenAI's GPT-3, which boasts 175 billion parameters.\n",
       "\n",
       "### Key Milestones and Influential Models\n",
       "\n",
       "Several key models have marked the evolution of LLMs:\n",
       "\n",
       "- **BERT (2018):** Developed by Google, BERT (Bidirectional Encoder Representations from Transformers) introduced a new pre-training approach that improved understanding of context in language tasks.\n",
       "- **GPT-2 (2019):** OpenAI's GPT-2 demonstrated the potential of generative pre-trained transformers, showcasing impressive text generation capabilities.\n",
       "- **T5 (2019):** Google's T5 (Text-to-Text Transfer Transformer) unified various NLP tasks under a single framework, further advancing the versatility of LLMs.\n",
       "- **GPT-3 (2020):** With 175 billion parameters, GPT-3 set a new benchmark for LLMs, demonstrating remarkable abilities in language understanding and generation.\n",
       "\n",
       "### Ongoing Developments\n",
       "\n",
       "The field of LLMs continues to evolve rapidly, with ongoing research focused on improving efficiency, reducing biases, and enhancing interpretability. The development of models like OpenAI's ChatGPT and Google's LaMDA highlights the continuous push towards more capable and human-like language models.\n",
       "\n",
       "In summary, the historical development of LLMs is characterized by a series of breakthroughs in model architecture, training techniques, and scaling laws. These advancements have collectively transformed the landscape of NLP, enabling machines to understand and generate human language with unprecedented accuracy and fluency.\n",
       "\n",
       "---\n",
       "\n",
       "### Theoretical Foundations of Scaling Laws\n",
       "\n",
       "Scaling laws in large language models (LLMs) are grounded in a set of mathematical models and principles that elucidate the relationship between model size, the volume of training data, and the resulting performance. These laws provide a framework for understanding how increasing the scale of a model can enhance its capabilities, offering insights into the potential and limitations of LLMs.\n",
       "\n",
       "#### Mathematical Models\n",
       "\n",
       "At the core of scaling laws are power-law relationships, which describe how performance metrics such as accuracy or loss improve as a function of model size and data quantity. These relationships are often expressed in the form:\n",
       "\n",
       "\\[ P(N, D) = a \\cdot N^b \\cdot D^c + \\epsilon \\]\n",
       "\n",
       "where \\( P \\) represents the performance metric, \\( N \\) is the number of parameters in the model, \\( D \\) is the amount of data, \\( a \\), \\( b \\), and \\( c \\) are constants derived from empirical observations, and \\( \\epsilon \\) is an error term accounting for noise and other factors.\n",
       "\n",
       "#### Principles of Scaling\n",
       "\n",
       "1. **Parameter Growth**: Increasing the number of parameters in a model generally leads to improved performance, as larger models can capture more complex patterns and nuances in the data. This principle is supported by the observation that larger models tend to have lower training and validation loss, indicating better generalization capabilities.\n",
       "\n",
       "2. **Data Scaling**: The amount of data available for training is equally crucial. As the dataset size increases, models can learn more diverse and comprehensive representations, which enhances their ability to generalize to unseen data. However, the benefits of additional data diminish as the model size grows, suggesting a saturation point where additional data yields minimal performance gains.\n",
       "\n",
       "3. **Compute Efficiency**: The efficiency of computation plays a significant role in scaling laws. Larger models require more computational resources, and the relationship between compute and performance is often sub-linear. This means that doubling the compute does not necessarily double the performance, highlighting the importance of optimizing computational strategies.\n",
       "\n",
       "#### Impact on LLM Capabilities\n",
       "\n",
       "The theoretical foundations of scaling laws suggest that there is a predictable trajectory of improvement as models and datasets grow. This has profound implications for the development of LLMs, as it provides a roadmap for achieving higher performance through scaling. However, it also underscores the challenges associated with resource allocation, as the costs of scaling can be substantial.\n",
       "\n",
       "Understanding these theoretical underpinnings allows researchers and practitioners to make informed decisions about model architecture, data collection, and resource investment, ultimately guiding the development of more powerful and efficient LLMs. As the field continues to evolve, these scaling laws will remain a critical component of the theoretical framework that drives innovation in natural language processing.\n",
       "\n",
       "---\n",
       "\n",
       "## Empirical Evidence and Case Studies\n",
       "\n",
       "### Introduction\n",
       "\n",
       "The development and deployment of large language models (LLMs) have been significantly influenced by scaling laws, which suggest that model performance improves predictably with increased model size, data, and computational resources. This section delves into empirical evidence supporting these scaling laws, drawing from a variety of experiments and real-world applications. We will explore case studies of prominent LLMs, examining both their successes and the challenges encountered during scaling.\n",
       "\n",
       "### Empirical Evidence Supporting Scaling Laws\n",
       "\n",
       "Recent research has consistently demonstrated that larger models tend to perform better across a range of natural language processing tasks. Studies have shown that as the number of parameters in a model increases, so does its ability to generalize and perform complex tasks. For instance, the work by Kaplan et al. (2020) provided a comprehensive analysis of scaling laws, showing that model performance scales predictably with the logarithm of the number of parameters, dataset size, and computational budget.\n",
       "\n",
       "In another study, Brown et al. (2020) introduced GPT-3, a model with 175 billion parameters, which exhibited remarkable capabilities in few-shot learning, outperforming smaller models on various benchmarks. This empirical evidence underscores the importance of scaling in achieving state-of-the-art performance in LLMs.\n",
       "\n",
       "### Case Studies of Prominent LLMs\n",
       "\n",
       "#### GPT-3\n",
       "\n",
       "GPT-3, developed by OpenAI, serves as a quintessential example of the power of scaling laws. With its massive parameter count, GPT-3 demonstrated unprecedented language understanding and generation capabilities. It excelled in tasks such as translation, question answering, and even creative writing, often requiring minimal task-specific fine-tuning. However, the model's size also posed challenges, including increased computational costs and environmental impact, highlighting the need for efficient scaling strategies.\n",
       "\n",
       "#### BERT and its Variants\n",
       "\n",
       "BERT (Bidirectional Encoder Representations from Transformers) and its subsequent variants, such as RoBERTa and DistilBERT, have also benefited from scaling. By increasing the model size and training data, these models have achieved superior performance on tasks like sentiment analysis and named entity recognition. The success of BERT and its derivatives illustrates the practical benefits of scaling, while also emphasizing the challenges of managing larger models, such as longer training times and the need for more sophisticated hardware.\n",
       "\n",
       "#### T5 (Text-to-Text Transfer Transformer)\n",
       "\n",
       "The T5 model, developed by Google Research, further exemplifies the advantages of scaling. By framing all NLP tasks as text-to-text problems, T5 leveraged scaling to achieve high performance across a wide array of tasks. The model's success in transfer learning scenarios underscores the potential of scaling to enhance model versatility and adaptability.\n",
       "\n",
       "### Challenges in Scaling LLMs\n",
       "\n",
       "While scaling has led to significant advancements, it also presents several challenges. The computational resources required for training and deploying large models are substantial, often limiting access to well-funded organizations. Additionally, the environmental impact of training large models has raised concerns, prompting research into more efficient training methods and architectures.\n",
       "\n",
       "Moreover, as models grow in size, they become more opaque, complicating efforts to interpret their decision-making processes. This lack of transparency can hinder trust and accountability, particularly in sensitive applications.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "Empirical evidence and case studies of prominent LLMs underscore the transformative potential of scaling laws in advancing natural language processing. While the successes of models like GPT-3, BERT, and T5 highlight the benefits of scaling, the associated challenges necessitate ongoing research into efficient and sustainable scaling practices. As the field continues to evolve, balancing performance gains with ethical and practical considerations will be crucial in harnessing the full potential of LLMs.\n",
       "\n",
       "---\n",
       "\n",
       "## Future Directions and Implications\n",
       "\n",
       "The future of Large Language Model (LLM) scaling laws is poised to significantly influence the trajectory of artificial intelligence research and its applications across various industries. As we continue to explore the boundaries of LLM capabilities, several potential advancements and challenges emerge, each carrying profound implications for the field.\n",
       "\n",
       "### Advancements in LLM Scaling\n",
       "\n",
       "1. **Enhanced Model Architectures**: Future advancements are likely to focus on refining model architectures to improve efficiency and performance. Innovations such as sparse models, which activate only a subset of parameters during inference, could lead to more scalable and cost-effective solutions.\n",
       "\n",
       "2. **Improved Training Techniques**: Techniques like transfer learning and continual learning are expected to evolve, allowing models to leverage existing knowledge more effectively and adapt to new information with minimal retraining. This could reduce the computational resources required for training large models.\n",
       "\n",
       "3. **Integration with Other AI Technologies**: The integration of LLMs with other AI technologies, such as reinforcement learning and computer vision, could lead to the development of more versatile and robust AI systems. This convergence may enable more complex and nuanced applications across different domains.\n",
       "\n",
       "### Challenges in LLM Scaling\n",
       "\n",
       "1. **Resource Constraints**: The computational and energy demands of training and deploying large-scale models remain a significant challenge. Addressing these constraints will require innovations in hardware, such as more efficient GPUs and TPUs, as well as software optimizations.\n",
       "\n",
       "2. **Data Limitations**: The quality and diversity of training data are critical for the performance of LLMs. Ensuring access to high-quality datasets while respecting privacy and ethical considerations will be a key challenge moving forward.\n",
       "\n",
       "3. **Model Interpretability and Bias**: As models grow in complexity, understanding their decision-making processes becomes increasingly difficult. Developing methods to interpret model outputs and mitigate biases will be essential to ensure fair and transparent AI systems.\n",
       "\n",
       "### Implications for AI Research and Industry\n",
       "\n",
       "1. **Accelerated Innovation**: The continued scaling of LLMs is likely to accelerate innovation in AI research, leading to breakthroughs in natural language understanding, generation, and other cognitive tasks. This could open new avenues for research and development across various scientific disciplines.\n",
       "\n",
       "2. **Industry Applications**: In industry, LLMs have the potential to revolutionize sectors such as healthcare, finance, and customer service by automating complex tasks and providing insights from vast amounts of data. However, the deployment of these models must be carefully managed to ensure reliability and security.\n",
       "\n",
       "3. **Ethical Considerations**: The ethical implications of LLM scaling are profound. Issues such as data privacy, algorithmic bias, and the potential for misuse must be addressed through robust governance frameworks and ethical guidelines. Ensuring that AI technologies are developed and used responsibly will be crucial for maintaining public trust.\n",
       "\n",
       "### Trajectory of LLM Development\n",
       "\n",
       "The trajectory of LLM development is likely to be characterized by a balance between scaling and specialization. While larger models may offer superior performance, there is a growing recognition of the need for models that are tailored to specific tasks and contexts. This shift towards more specialized models could lead to more efficient and effective AI systems that are better aligned with human values and societal needs.\n",
       "\n",
       "In conclusion, the future of LLM scaling laws presents both exciting opportunities and formidable challenges. By navigating these complexities with foresight and responsibility, the AI community can harness the full potential of LLMs to drive progress and innovation across diverse fields."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = orchestrator_worker.invoke({\"research_topic\": \"Create a report on LLM scaling laws\"})\n",
    "\n",
    "Markdown(state[\"final_report\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saurav-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
