{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant. Answer all questions to the best of your ability.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg = chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Can you explain Dynamic Programming under 50 words?\")\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 1: Pass Chat History to your LLM as a context.\n",
    "\n",
    "chat_history = [\n",
    "    HumanMessage(content=\"Can you explain Dynamic Programming under 50 words?\"),\n",
    "    AIMessage(content=ai_msg.content)\n",
    "]\n",
    "\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interrogate_model(chat_history: list, preserve_chat_history=True):\n",
    "    current_message = [HumanMessage(content=\"What did I ask you earlier?\")]\n",
    "    chat_messages = []\n",
    "\n",
    "    if preserve_chat_history:\n",
    "        chat_messages = chat_history + current_message\n",
    "    else:\n",
    "        chat_messages = current_message\n",
    "\n",
    "\n",
    "    ai_msg = chain.invoke(\n",
    "        {\n",
    "            \"messages\": chat_messages\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interrogate_model(chat_history, preserve_chat_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Summarize the chat history\n",
    "\n",
    "def summarize_chat_history(chat_history: list):\n",
    "    \"\"\" Summarizes the chat history when the message count is greater than 4.\"\"\"\n",
    "\n",
    "    if len(chat_history) >= 4:\n",
    "        summary_prompt = (\n",
    "            \"Distill the above chat messages into a single summary message. \"\n",
    "            \"Include as many specific details as you can.\"\n",
    "        )\n",
    "        print(chat_history)\n",
    "        summary_message = chain.invoke(\n",
    "            chat_history + [HumanMessage(content=summary_prompt)]\n",
    "        )\n",
    "\n",
    "        return summary_message.content\n",
    "    \n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interrogate_model_with_summary(query: str, chat_history: list, debug_mode=False):\n",
    "    current_message = [HumanMessage(content=query)]\n",
    "    chat_messages = []\n",
    "\n",
    "    if len(chat_history) >= 4:\n",
    "        print(\"Summarizing your content...\")\n",
    "        summary_message = summarize_chat_history(chat_history)\n",
    "        chat_messages = [AIMessage(content=summary_message)] + current_message\n",
    "    else:\n",
    "        chat_messages = chat_history + current_message\n",
    "    \n",
    "    if debug_mode:\n",
    "        print(\"Messages sent to the model:\")\n",
    "        print(chat_messages, \"\\n\")\n",
    "\n",
    "    ai_msg = chain.invoke(\n",
    "        {\n",
    "            \"messages\": chat_messages\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return AIMessage(content=ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_model(query: str, chat_history: list, debug_mode=False):\n",
    "    query_response = interrogate_model_with_summary(query, chat_history, debug_mode)\n",
    "    \n",
    "    # Append the query and response to the chat history\n",
    "    chat_history.append(HumanMessage(content=query))\n",
    "    chat_history.append(query_response)\n",
    "    \n",
    "    return query_response, chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages sent to the model:\n",
      "[HumanMessage(content='Can you explain Dynamic Programming under 50 words?', additional_kwargs={}, response_metadata={})] \n",
      "\n",
      "Dynamic Programming is a method for solving complex problems by breaking them down into simpler subproblems, solving each subproblem just once, and storing their solutions. This approach is particularly useful for optimization problems and helps avoid redundant calculations.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "query1 = \"Can you explain Dynamic Programming under 50 words?\"\n",
    "query_response1, chat_history = chat_with_model(query1, chat_history, debug_mode=True)\n",
    "\n",
    "print(query_response1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages sent to the model:\n",
      "[HumanMessage(content='Can you explain Dynamic Programming under 50 words?', additional_kwargs={}, response_metadata={}), AIMessage(content='Dynamic Programming is a method for solving complex problems by breaking them down into simpler subproblems, solving each subproblem just once, and storing their solutions. This approach is particularly useful for optimization problems and helps avoid redundant calculations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you explain Graph data structures under 50 words?', additional_kwargs={}, response_metadata={})] \n",
      "\n",
      "Graph data structures consist of nodes (vertices) connected by edges. They can represent relationships or connections in various contexts, like social networks or transportation systems. Graphs can be directed or undirected, weighted or unweighted, and are commonly used in algorithms for traversal, searching, and optimization.\n"
     ]
    }
   ],
   "source": [
    "query2 = \"Can you explain Graph data structures under 50 words?\"\n",
    "query_response2, chat_history = chat_with_model(query2, chat_history, debug_mode=True)\n",
    "\n",
    "print(query_response2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing your content...\n",
      "[HumanMessage(content='Can you explain Dynamic Programming under 50 words?', additional_kwargs={}, response_metadata={}), AIMessage(content='Dynamic Programming is a method for solving complex problems by breaking them down into simpler subproblems, solving each subproblem just once, and storing their solutions. This approach is particularly useful for optimization problems and helps avoid redundant calculations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you explain Graph data structures under 50 words?', additional_kwargs={}, response_metadata={}), AIMessage(content='Graph data structures consist of nodes (vertices) connected by edges. They can represent relationships or connections in various contexts, like social networks or transportation systems. Graphs can be directed or undirected, weighted or unweighted, and are commonly used in algorithms for traversal, searching, and optimization.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you tell me what did I ask till now?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"You haven't asked any specific questions until now. Your previous message mentioned dynamic programming and graph data structures, but you did not pose any specific queries. If you have a question or topic you'd like to discuss, feel free to ask!\", additional_kwargs={}, response_metadata={})]\n",
      "Messages sent to the model:\n",
      "[AIMessage(content='In this chat, you requested explanations of two concepts: Dynamic Programming and Graph data structures. For Dynamic Programming, I described it as a method for solving complex problems by breaking them into simpler subproblems and storing their solutions. For Graph data structures, I explained that they consist of nodes connected by edges and can represent relationships in various contexts. Graphs can be directed or undirected and weighted or unweighted. You later asked me to summarize our conversation, noting that you had not posed any specific questions beyond these explanations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you tell me what did I ask till now?', additional_kwargs={}, response_metadata={})] \n",
      "\n",
      "You asked me to explain two concepts: Dynamic Programming and Graph data structures. You also requested a summary of our conversation. Additionally, you inquired if I could tell you what you've asked so far.\n"
     ]
    }
   ],
   "source": [
    "query3 = \"Can you tell me what did I ask till now?\"\n",
    "query_response3, chat_history = chat_with_model(query3, chat_history, debug_mode=True)\n",
    "\n",
    "print(query_response3.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saurav-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
