{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Programming is a method for solving complex problems by breaking them down into simpler subproblems, solving each subproblem just once, and storing their solutions. It is often used for optimization problems where overlapping subproblems and optimal substructure properties exist.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant. Answer all questions to the best of your ability.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "ai_msg = chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Can you explain Dynamic Programming under 50 words?\")\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Can you explain Dynamic Programming under 50 words?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Dynamic Programming is a method for solving complex problems by breaking them down into simpler subproblems, solving each subproblem just once, and storing their solutions. It is often used for optimization problems where overlapping subproblems and optimal substructure properties exist.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Method 1: Pass Chat History to your LLM as a context.\n",
    "\n",
    "chat_history = [\n",
    "    HumanMessage(content=\"Can you explain Dynamic Programming under 50 words?\"),\n",
    "    AIMessage(content=ai_msg.content)\n",
    "]\n",
    "\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interrogate_model(chat_history: list, preserve_chat_history=True):\n",
    "    current_message = [HumanMessage(content=\"What did I ask you earlier?\")]\n",
    "    chat_messages = []\n",
    "\n",
    "    if preserve_chat_history:\n",
    "        chat_messages = chat_history + current_message\n",
    "    else:\n",
    "        chat_messages = current_message\n",
    "\n",
    "\n",
    "    ai_msg = chain.invoke(\n",
    "        {\n",
    "            \"messages\": chat_messages\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have the ability to recall past conversations or remember any previous interactions. Each session is treated independently. How can I assist you today?\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interrogate_model(chat_history, preserve_chat_history=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Trimming off the Chat History"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saurav-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
