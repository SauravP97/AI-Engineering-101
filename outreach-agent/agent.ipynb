{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sauravprateek/Documents/Agentic Workflows/saurav-env/lib/python3.13/site-packages/pydantic/v1/validators.py:645: RuntimeWarning: coroutine 'get_profile_data' was never awaited\n",
      "  return any(getattr(config, name) not in {None, self.ignored_value} for name in self.config_attr_names)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profile_content(profile) -> str:\n",
    "    \"\"\" Get Profile data from Linkedin profile url or from a Profile file.\"\"\"\n",
    "    profile = open('./profiles/' + profile, 'r')\n",
    "    profile_content = profile.read()\n",
    "    return profile_content\n",
    "\n",
    "\n",
    "def extract_receiver_profile_information(profile_content) -> str:\n",
    "    \"\"\"Extract useful information from the profile content.\"\"\"\n",
    "\n",
    "    query = \"Get Profile details like name, organization and current role from the profile content.\"\n",
    "    model = ChatOpenAI(model=\"gpt-4o\")\n",
    "    response = model.invoke([\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that extracts profile details from the provided content.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Profile URL: {profile_content} \\n\\n Question: {query}\"}\n",
    "        ])\n",
    "    \n",
    "    return response.content\n",
    "\n",
    "def extract_candidate_profile_information(profile_content) -> str:\n",
    "    \"\"\"Extract useful information from the candidate profile content.\"\"\"\n",
    "\n",
    "    query = \"Get Profile details like name, organization, current role, experience and skill from the profile content.\"\n",
    "    model = ChatOpenAI(model=\"gpt-4o\")\n",
    "    response = model.invoke([\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that extracts profile details from the provided content.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Profile URL: {profile_content} \\n\\n Question: {query}\"}\n",
    "        ])\n",
    "    \n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Name:** Zach Johnson  \n",
      "- **Organization:** Mindera  \n",
      "- **Current Role:** Co-Founder and Head of AI Product  \n",
      "\n",
      "- **Name:** John Doe\n",
      "- **Current Organization:** UBS\n",
      "- **Current Role:** Senior Software Engineer\n",
      "- **Experience:**\n",
      "  - Senior Software Engineer at UBS, Zurich, Switzerland (2018 - 2025)\n",
      "  - Software Engineer at Easter Genetics, Uster, Switzerland (2015 - 2018)\n",
      "  - Research Assistant at ETH Zurich, Zurich, Switzerland (2012 - 2015)\n",
      "- **Skills:**\n",
      "  - Languages: Java, Python, C++\n",
      "  - Frameworks/Tools: Spring Boot, AWS, OpenCV, MATLAB\n",
      "  - Methodologies: Agile development methodologies\n",
      "  - Systems: Version control systems like Git\n",
      "  - Strengths: Building scalable and maintainable systems, strong background in object-oriented programming, data structures, and software design patterns, collaborative team player, excellent communication skills.\n"
     ]
    }
   ],
   "source": [
    "CANDIDATE_PROFILE = 'profile2.txt'\n",
    "RECEIVER_PROFILE = 'profile1.txt'\n",
    "\n",
    "receiver_profile_content = get_profile_content(RECEIVER_PROFILE)\n",
    "receiver_profile_information = extract_receiver_profile_information(receiver_profile_content)\n",
    "\n",
    "candidate_profile_content = get_profile_content(CANDIDATE_PROFILE)\n",
    "candidate_profile_information = extract_candidate_profile_information(candidate_profile_content)\n",
    "\n",
    "print(receiver_profile_information)\n",
    "print(candidate_profile_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_a_referral_pitch(receiver_information, candidate_information):\n",
    "    \"\"\" Write a referral pitch based on the receiver's and candidate profile information.\"\"\"\n",
    "    query = '''\n",
    "    You are a candidate applying to a role.\n",
    "    Write a referral pitch for applying to an open position in the receiver's organization \n",
    "    based on the receiver's profile information and the candidate profile information. \n",
    "    The receiver profile information and candidate profile information is provided to you and \n",
    "    the receiver information has the receiver name, organization, and current role.\n",
    "    The candidate profile information has the candidate name, organization, current role, experience, and skills.\n",
    "    \n",
    "    The pitch should be concise, professional, and highlight the candidate's skills and\n",
    "    experiences that make them a good fit for the position.\n",
    "\n",
    "    Keep the pitch message concise and to the point, under 100 words.\n",
    "    '''\n",
    "\n",
    "    model = ChatOpenAI(model=\"gpt-4o\")\n",
    "    response = model.invoke([\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"You are the Candidate trying to write a referral pitch for applying to an open position in the receiver's organization.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"Receiver Information: {receiver_information} \\n\\n Candidate Information: {candidate_information} \\n\\n Question: {query}\"\n",
    "            }\n",
    "        ])\n",
    "    \n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "referral_pitch = write_a_referral_pitch(receiver_profile_information, candidate_profile_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Referral for Position at Mindera\n",
      "\n",
      "Hi Zach,\n",
      "\n",
      "I'm writing to express my interest in joining Mindera's team. With over 8 years of experience in software engineering, including scalable system development at UBS, my skills in Java, Python, and AWS align well with Mindera's AI product initiatives. My strong background in object-oriented programming, coupled with my expertise in Agile methodologies and collaborative problem-solving, makes me a great fit for your innovative environment. I am excited about the prospect of contributing to Mindera's success and would appreciate any opportunity to discuss how I can support your team.\n",
      "\n",
      "Best,  \n",
      "John Doe\n"
     ]
    }
   ],
   "source": [
    "print(referral_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saurav-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
