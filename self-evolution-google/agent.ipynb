{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13865df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_tavily import TavilySearch\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "230fcc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(search_query: str, web_results: str, environment_feedback: str, model: ChatGoogleGenerativeAI) -> str:\n",
    "    print(\"Generating answer...\")\n",
    "    prompt = (\n",
    "        \"\"\"\n",
    "        Given the search query, web results and environment feedback, provide a concise and accurate answer.\n",
    "        \n",
    "        1. Search Query: {search_query}\n",
    "        2. Web Results: {web_results}\n",
    "        3. Environment Feedback: {environment_feedback}\n",
    "\n",
    "        Focus on Facts: Prioritize numbers, dates, definitions, and distinct arguments.\n",
    "        If environment feedback is provided, incorporate it into the answer.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    return model.invoke(\n",
    "        prompt.format(\n",
    "            search_query=search_query, \n",
    "            web_results=web_results, \n",
    "            environment_feedback=environment_feedback\n",
    "        )\n",
    "    ).content\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5327626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Perform a web search and return the results\"\"\"\n",
    "    print(\"Performing Web Search...\")\n",
    "\n",
    "    web_search_tool = TavilySearch(max_results=20)\n",
    "    web_results = web_search_tool.invoke({\"query\": query})\n",
    "\n",
    "    return _parse_web_search_results(web_results)\n",
    "\n",
    "\n",
    "def _parse_web_search_results(web_search_result) -> str:\n",
    "    \"\"\"Parse the web search results and filter based on relevance score\"\"\"\n",
    "\n",
    "    if not web_search_result or \"results\" not in web_search_result:\n",
    "        return \"\"\n",
    "\n",
    "    search_answers = []\n",
    "    for result in web_search_result[\"results\"]:\n",
    "        search_content = result[\"content\"]\n",
    "        search_answers.append(search_content)\n",
    "\n",
    "    return '\\n'.join(search_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "955a980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_environment_feedback(answer: str, search_query: str, web_results: str) -> str:\n",
    "    print(\"Generating Environment Feedback...\")\n",
    "    prompt = (\n",
    "        \"\"\"\n",
    "        Given the answer, search query, and web results, provide feedback on the answer provided for the search query.\n",
    "        Keep the feedback concise and focused on factual accuracy.\n",
    "        Take the Web Results as a source of truth when evaluating the answer.\n",
    "        \n",
    "        1. Answer: {answer}\n",
    "        2. Search Query: {search_query}\n",
    "        3. Web Results: {web_results}\n",
    "        \"\"\"\n",
    "    )\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\",)\n",
    "\n",
    "    return model.invoke(\n",
    "        prompt.format(\n",
    "            answer=answer,\n",
    "            search_query=search_query,\n",
    "            web_results=web_results\n",
    "        )\n",
    "    ).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99bb9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_REFINEMENTS = 3\n",
    "\n",
    "def start_self_evolution(model: ChatGoogleGenerativeAI, search_query: str):\n",
    "    refinement_count = 0\n",
    "    answer = \"\"\n",
    "    environment_feedback = \"\"\n",
    "    web_results = web_search(search_query)\n",
    "\n",
    "    while refinement_count < MAX_REFINEMENTS:\n",
    "        print(f\"Refinement Iteration: {refinement_count + 1}\")\n",
    "        answer = generate_answer(search_query, web_results, environment_feedback, model)\n",
    "        environment_feedback = get_environment_feedback(answer, search_query, web_results)\n",
    "        refinement_count += 1\n",
    "    \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f58b1de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidates_crossover(evolved_answers: list[str], search_query: str) -> str:\n",
    "    \"\"\"Combine multiple evolved answers into a single answer\"\"\"\n",
    "    print(\"Performing Crossover of Candidates...\")\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\")\n",
    "    prompt = (\n",
    "        \"\"\"\n",
    "        Your task is to research a topic and try to fulfill the user query in the <user> tags.\n",
    "        <instructions>\n",
    "        You are given a list of candidate answers in <answer_list> tags below. Combine them into a single answer so that,\n",
    "        + it best fulfills the initial user query in the <user> tags.\n",
    "        + If there are conflicting information, try to reconcile them in a logically sound way.\n",
    "        </instructions>\n",
    "        Here is the user query.\n",
    "        <user>\n",
    "        {query}\n",
    "        </user>\n",
    "        Here is the list of candidate answers you need to merge.\n",
    "        <answer_list>\n",
    "        {answer_list}\n",
    "        </answer_list>\n",
    "        Only output a combined answer from the answers in <answer_list>. Do NOT use other information.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    return model.invoke(\n",
    "        prompt.format(\n",
    "            query=search_query,\n",
    "            answer_list='\\n'.join(\n",
    "                [ f\"Candidate Answer: {evolved_answer}\" for evolved_answer in evolved_answers]\n",
    "            )\n",
    "        )\n",
    "    ).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a02af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "CANDIDATES = 3\n",
    "CANDIDATES_CONFIGURATION = [\n",
    "    {\n",
    "        \"top_k\": 30,\n",
    "        \"temperature\": 0.5,\n",
    "    },\n",
    "    {\n",
    "        \"top_k\": 40,\n",
    "        \"temperature\": 1.0,\n",
    "    },\n",
    "    {\n",
    "        \"top_k\": 50,\n",
    "        \"temperature\": 1.5,\n",
    "    },\n",
    "]\n",
    "\n",
    "def perform_self_evolution(search_query: str):\n",
    "    evolved_answers = []\n",
    "    for index, candidate_config in enumerate(CANDIDATES_CONFIGURATION):\n",
    "        print(f\"\\n Spawning Candidate: {index + 1} \\n\")\n",
    "        model = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.5-pro\",\n",
    "            temperature=candidate_config[\"temperature\"],\n",
    "            top_k=candidate_config[\"top_k\"],\n",
    "        )\n",
    "        evolved_answer = start_self_evolution(model, search_query)\n",
    "        evolved_answers.append(evolved_answer)\n",
    "    \n",
    "    return candidates_crossover(evolved_answers, search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3174942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Spawning Candidate: 1 \n",
      "\n",
      "Performing Web Search...\n",
      "Refinement Iteration: 1\n",
      "Generating answer...\n",
      "Generating Environment Feedback...\n",
      "Refinement Iteration: 2\n",
      "Generating answer...\n",
      "Generating Environment Feedback...\n",
      "Refinement Iteration: 3\n",
      "Generating answer...\n",
      "Generating Environment Feedback...\n",
      "\n",
      " Spawning Candidate: 2 \n",
      "\n",
      "Performing Web Search...\n",
      "Refinement Iteration: 1\n",
      "Generating answer...\n",
      "Generating Environment Feedback...\n",
      "Refinement Iteration: 2\n",
      "Generating answer...\n",
      "Generating Environment Feedback...\n",
      "Refinement Iteration: 3\n",
      "Generating answer...\n",
      "Generating Environment Feedback...\n",
      "\n",
      " Spawning Candidate: 3 \n",
      "\n",
      "Performing Web Search...\n",
      "Refinement Iteration: 1\n",
      "Generating answer...\n",
      "Generating Environment Feedback...\n",
      "Refinement Iteration: 2\n",
      "Generating answer...\n",
      "Generating Environment Feedback...\n",
      "Refinement Iteration: 3\n",
      "Generating answer...\n",
      "Generating Environment Feedback...\n",
      "Performing Crossover of Candidates...\n",
      "\n",
      " Final Evolved Answer after Crossover: \n",
      "\n",
      "Based on the provided information, the investment philosophies of Duan Yongping, Warren Buffett, and Charlie Munger are rooted in long-term, value-driven investing with a shared emphasis on discipline and patience.\n",
      "\n",
      "**Duan Yongping:**\n",
      "Often called the \"Chinese Warren Buffett,\" Duan Yongping practices a high-conviction, value-driven, and long-term investment strategy. His philosophy is defined by:\n",
      "*   **A Concentrated Portfolio:** He typically holds a small number of stocks, around 8 to 12.\n",
      "*   **The \"Slow is fast\" Mantra:** This principle emphasizes deliberate decision-making to avoid major mistakes, which he believes is the key to achieving long-term wealth.\n",
      "*   **Three Core Pillars (learned from Buffett):**\n",
      "    1.  Never invest in something you don’t understand.\n",
      "    2.  Never borrow to invest.\n",
      "    3.  Never short stocks.\n",
      "*   **Strategy:** He focuses on finding companies with enduring competitive moats, prioritizing valuation over market timing, and exercising patience.\n",
      "\n",
      "**Warren Buffett:**\n",
      "Buffett's core philosophy is distilled into three key rules that he shared with Duan Yongping, reflecting a deep emphasis on understanding the underlying business and avoiding unnecessary risk:\n",
      "1.  Never invest in something you don’t understand.\n",
      "2.  Never use borrowed money to invest.\n",
      "3.  Never short stocks.\n",
      "\n",
      "**Charlie Munger:**\n",
      "Munger's philosophy centered on a disciplined, rational, \"buy-and-hold strategy\" designed to achieve steady, compounding returns over time. His core principles were:\n",
      "*   **Patience and Selectivity:** His primary lesson was to \"choose a small number of strong companies, buy them at a fair price, and hold them with patience.\"\n",
      "*   **Focus on Quality and Price:** He would wait for strong companies with a \"competitive moat\" to become underpriced before making an investment.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "query = \"What are the investment philosophies of Duan Yongping, Warren Buffett, and Charlie Munger?\"\n",
    "crossover_evolved_answer = perform_self_evolution(query)\n",
    "print(\"\\n Final Evolved Answer after Crossover: \\n\")\n",
    "print(crossover_evolved_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb07c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_without_self_evolution(search_query: str) -> str:\n",
    "    web_results = web_search(search_query)\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\")\n",
    "    answer = generate_answer(search_query, web_results, \"\", model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf8c2f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Web Search...\n",
      "Generating answer...\n",
      "\n",
      " Search Answer without Self Evolution: \n",
      "\n",
      "Based on the provided web results, here are the investment philosophies of Duan Yongping, Warren Buffett, and Charlie Munger:\n",
      "\n",
      "*   **Duan Yongping**: Known as the \"Chinese Warren Buffett,\" Duan practices a high-conviction, value-driven, long-term investment strategy. His philosophy centers on a concentrated portfolio of 8–12 stocks, focusing on companies with \"enduring moats.\" His mantra is \"Slow is fast,\" emphasizing deliberate decisions to avoid major mistakes. After a 2006 lunch with Buffett, he adopted three pillars for his philosophy: never invest in what you don't understand, never borrow to invest, and never short stocks.\n",
      "\n",
      "*   **Warren Buffett**: His investment philosophy, as conveyed to Duan Yongping, is built on three core rules:\n",
      "    1.  Never invest in something you don’t understand.\n",
      "    2.  Never borrow money to invest.\n",
      "    3.  Never short stocks.\n",
      "\n",
      "*   **Charlie Munger**: Munger's philosophy was a long-term, \"buy-and-hold strategy\" focused on compounding returns. His core principle was to choose a small number of strong companies, buy them at a fair price, and hold them with patience and unwavering conviction. He emphasized rationality and waiting for an investment to become underpriced before buying.\n"
     ]
    }
   ],
   "source": [
    "search_answer = search_without_self_evolution(query)\n",
    "print(\"\\n Search Answer without Self Evolution: \\n\")\n",
    "print(search_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saurav-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
