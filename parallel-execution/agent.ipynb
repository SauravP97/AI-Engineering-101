{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_content(article_name: str) -> str:\n",
    "    \"\"\" Function to get the content of an article.\"\"\"\n",
    "    profile = open('./articles/' + article_name, 'r')\n",
    "    profile_content = profile.read()\n",
    "    return profile_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bloom_filter_article_summary():\n",
    "    \"\"\" Function to get the summary of the Bloom Filter article.\"\"\"\n",
    "    article_name = 'bloom-filters.txt'\n",
    "    article_content = get_article_content(article_name)\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0.0)\n",
    "    \n",
    "    response = llm.invoke(\n",
    "        f\"Summarize the following article:\\n\\n{article_content}\\n\\n\"\n",
    "        \"Please provide a concise summary that captures the main points. Please keep the summary under 200 words.\"\n",
    "    )\n",
    "    \n",
    "    return response.content.strip() if response else \"No summary available.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_db_article_summary():\n",
    "    \"\"\" Function to get the summary of the Graph database article.\"\"\"\n",
    "    article_name = 'graph-db.txt'\n",
    "    article_content = get_article_content(article_name)\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0.0)\n",
    "    \n",
    "    response = llm.invoke(\n",
    "        f\"Summarize the following article:\\n\\n{article_content}\\n\\n\"\n",
    "        \"Please provide a concise summary that captures the main points. Please keep the summary under 200 words.\"\n",
    "    )\n",
    "    \n",
    "    return response.content.strip() if response else \"No summary available.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom_filter_summary = get_bloom_filter_article_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_db_summary = get_graph_db_article_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloom Filters are compact data structures used to determine if an element is part of a set. They can respond in two ways: \"Maybe\", indicating there is some probability the element is in the set, and \"Definitely Not\", indicating zero probability the element is in the set. Bloom Filters can always recognize true negatives but may generate false positives. They are used in scenarios where false positives are acceptable. A standard Bloom Filter can be implemented using a group of hash functions and works most efficiently when the size of the search space is known in advance. The process of inserting an element into the Bloom Filter involves computing the hash value of the element with all the hash functions and setting the corresponding addresses in the Bloom Filter vector to 1. To search for an element, the hash of the element is computed with all the hash functions and the corresponding locations in the Bloom Filter vector are checked. The run time complexity of both operations is O(K), where K is the number of distinct hash functions used.\n"
     ]
    }
   ],
   "source": [
    "print(bloom_filter_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4J is a popular graph database that stores data in nodes and relationships, rather than traditional tables or documents. The data model in Neo4J is composed of nodes, relationships, and properties. Nodes are the core entities in the database, each with a label that determines its type. Each node can also have multiple properties, described in key-value pairs. Nodes can be related to each other through relationships, which are equivalent to edges in the graph data structure. Unlike in the graph data structure, in Neo4J it is mandatory to add a direction when creating a relationship between two nodes. However, Neo4J allows querying an undirected relationship, making the queries flexible. Cypher is Neo4J's graph query language that allows users to create nodes with specific properties, create relationships between nodes, and query or visualize the nodes and their relationships.\n"
     ]
    }
   ],
   "source": [
    "print(graph_db_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saurav-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
